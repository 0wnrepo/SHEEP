{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontend.database import session\n",
    "from scripts import generate_fc_layer_circuit, benchmark_utils\n",
    "from scripts.circuit import circuit\n",
    "from scripts.particles import variables, enc_vec, enc_mat, enc_tensor3\n",
    "from scripts.reusable_modules import oneb_adder, nb_adder\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.functions import reduce_add\n",
    "inp = enc_vec(name='in', nb=4)\n",
    "out = enc_vec(name='out', nb=3)\n",
    "ra = reduce_add('adder', inp, out)\n",
    "ra_obj = circuit('reduce_add', ra)\n",
    "ra_obj.write_file(filename='./test.sheep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB bit adder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,1,1,1,0,1,0 has 9 ones.\n",
      "0,1,0,1,0,0,0,1,0,0,1,1,0,0,1,1,0,1,1,0,0,0,1,0,1 has 11 ones.\n",
      "Time taken is 1.0 sec\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "nb = 25\n",
    "depth = int(math.floor(math.log(nb, 2)))\n",
    "samples=2\n",
    "inp = enc_vec(name='in', nb=nb)\n",
    "out = enc_vec(name='out', nb=depth+1)\n",
    "ra = reduce_add('adder', inp, out)\n",
    "ra_obj = circuit('reduce_add', ra)\n",
    "ra_obj.write_file(filename='./test.sheep')\n",
    "processing_time = np.zeros(samples)\n",
    "for idx in range(0, samples):\n",
    "    inp_arr_val = list(map(lambda x : int(x), np.random.uniform(size=nb)> 0.5))\n",
    "    inp_dict = inp.get_input_dict(inp_arr_val)\n",
    "    inputs_file = benchmark_utils.write_inputs_file(inp_dict)\n",
    "    results = benchmark_utils.run_circuit('./test.sheep',inputs_file,\"bool\",\"TFHE\", eval_strategy='parallel')\n",
    "    processing_time[idx] = results['Processing times (s)']['circuit_evaluation']\n",
    "    out_vars = out.get_variables()\n",
    "    err_str = str(''.join(results['Outputs'][var] for var in out_vars)[::-1]) +\" -- \"+ str(np.asarray(inp_arr_val).sum())\n",
    "    assert int(''.join(results['Outputs'][var] for var in out_vars)[::-1], 2) == np.asarray(inp_arr_val).sum(), err_str\n",
    "    print \",\".join(map(lambda x: str(x), inp_arr_val))+\" has \" + str(int(''.join(results['Outputs'][var] for var in out_vars)[::-1], 2))+\" ones.\"\n",
    "print \" \".join([\"Time taken is\" , str(processing_time.mean()),'sec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single output linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken is 0.453885 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.nn_layer import linear_layer_1d\n",
    "from tqdm import tqdm\n",
    "nb = 10\n",
    "samples = 2\n",
    "inputs = enc_vec(name='nn_input', nb=nb)\n",
    "depth = int(math.ceil(math.log(nb*1.0, 2)))\n",
    "outputs = enc_vec(name='nn_outputs', nb=1)\n",
    "outputs_sum = enc_vec(name='sum_outputs', nb=depth+1)\n",
    "weight = np.asarray(list(map(lambda x : int(x), np.random.uniform(size=nb)> 0.5)))\n",
    "layer = linear_layer_1d(name='linear', weight=weight,\n",
    "                    inputs=inputs, outputs=outputs)\n",
    "layer_obj = circuit('linear_layer', layer, const_inputs=[])\n",
    "layer_obj.write_file(filename='./test_linear.sheep')\n",
    "processing_time = np.zeros(samples)\n",
    "for idx in tqdm(range(0, samples)):\n",
    "    inp_arr_val = list(map(lambda x : int(x), np.random.uniform(size=nb)> 0.5))\n",
    "    inp_dict = inputs.get_input_dict(inp_arr_val)\n",
    "    inputs_file = benchmark_utils.write_inputs_file(inp_dict)\n",
    "    results = benchmark_utils.run_circuit('./test_linear.sheep',inputs_file,\"bool\",\"TFHE\",eval_strategy='parallel')\n",
    "    processing_time[idx] = results['Processing times (s)']['circuit_evaluation']\n",
    "    out_vars = outputs.get_variables()\n",
    "    xor_val = (weight == np.asarray([x for x in inp_arr_val]))\n",
    "    err_str = str(''.join(results['Outputs'][var] for var in out_vars)[::-1]) +\" -- \"+ str(np.asarray(xor_val).sum())\n",
    "    assert int(''.join(results['Outputs'][var] for var in out_vars)[::-1], 2) == int(np.asarray(xor_val).sum()>nb/2), err_str\n",
    "print \" \".join([\"Time taken is\" , str(processing_time.mean()),'sec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Numbers (Ciphertext with Plaintext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125(CP) is smaller than 126(PT)\n",
      "Time taken is 0.35243 sec\n"
     ]
    }
   ],
   "source": [
    "from scripts.reusable_modules import compare_cp\n",
    "cp_inp_val = [1, 0, 1, 1, 1, 1, 1]\n",
    "tgt = 126\n",
    "comp_inp = enc_vec(name='cp_inp',nb = len(cp_inp_val))\n",
    "out_vec = enc_vec(name='cp_out', nb=1)\n",
    "cp_circ = compare_cp(name='cp', inputs=(comp_inp, tgt), outputs=out_vec)\n",
    "sum_obj = circuit('cp', cp_circ)\n",
    "sum_obj.write_file(filename='./test_cp.sheep')\n",
    "inputs_file = benchmark_utils.write_inputs_file(comp_inp.get_input_dict(cp_inp_val))\n",
    "results = benchmark_utils.run_circuit('./test_cp.sheep',inputs_file,\"bool\",\"TFHE\",eval_strategy='parallel')\n",
    "processing_time[idx] = results['Processing times (s)']['circuit_evaluation']\n",
    "assert (int(results['Outputs'][out_vec.get_variables()[0]]) == int(int(''.join(map(lambda x : str(x), cp_inp_val)),2) >= tgt))\n",
    "if int(results['Outputs'][out_vec.get_variables()[0]]) == 1:\n",
    "    print str( int(int(''.join(map(lambda x : str(x), cp_inp_val[::-1])),2)))+\"(CP) is greater than \"+str(tgt)+str(\"(PT)\")\n",
    "else:\n",
    "    print str( int(int(''.join(map(lambda x : str(x), cp_inp_val[::-1])),2)))+\"(CP) is smaller than \"+str(tgt)+str(\"(PT)\")\n",
    "print \" \".join([\"Time taken is\" , results['Processing times (s)']['circuit_evaluation'],'sec'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.nn_layer import linear_layer\n",
    "from tqdm import tqdm\n",
    "nb = 10\n",
    "samples = 1\n",
    "num_out= 3\n",
    "depth = int(math.ceil(math.log(nb*1.0, 2)))\n",
    "inputs = enc_mat(name='nn_input'+str(idx)+'_', size= (1, nb))\n",
    "outputs = enc_mat(name='nn_outputs'+str(idx)+'_', size=(num_out, 1))\n",
    "weight = (np.random.uniform(size=(num_out, nb))> 0.5).astype(int)\n",
    "layer = linear_layer(name='linear', weight=weight,\n",
    "                    inputs=inputs, outputs=outputs)\n",
    "layer_obj = circuit('linear_layer', layer, const_inputs=[])\n",
    "layer_obj.write_file(filename='./test_linear.sheep')\n",
    "processing_time = np.zeros(samples)\n",
    "for idx in tqdm(range(0, samples)):\n",
    "    inp_arr_val = list(map(lambda x : int(x), np.random.uniform(size=nb*1)> 0.5))\n",
    "    inp_dict = inputs.get_input_dict(inp_arr_val)\n",
    "    inputs_file = benchmark_utils.write_inputs_file(inp_dict)\n",
    "    results = benchmark_utils.run_circuit('./test_linear.sheep',inputs_file,\"bool\",\"TFHE\",eval_strategy='parallel')\n",
    "    processing_time[idx] = results['Processing times (s)']['circuit_evaluation']\n",
    "    out_vars = outputs.get_variables()\n",
    "    xor_val = (weight == np.asarray([x for x in inp_arr_val]))\n",
    "    #print(xor_val)\n",
    "    out_bit_vec = np.asarray([int(results['Outputs'][var]) for var in out_vars])\n",
    "    true_bit_vec = (np.sum(np.asarray(xor_val), axis=1)>nb/2).astype(int)\n",
    "    assert np.alltrue(out_bit_vec == true_bit_vec)\n",
    "print(processing_time.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Input Dim | Output Dim | Time|\n",
    "|:---------| :---------- |:---:|\n",
    "|100       |    10      | 48s |\n",
    "|500       |    2       | 47s |\n",
    "|1024      |    10      | 487s|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scripts.particles import enc_mat\n",
    "\n",
    "\n",
    "def im2col(name, x, hh, ww, stride):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x: image matrix to be translated into columns, (C,H,W)\n",
    "      hh: filter height\n",
    "      ww: filter width\n",
    "      stride: stride\n",
    "    Returns:\n",
    "      col: (new_h*new_w,hh*ww*C) matrix, each column is a\n",
    "           cube that will convolve with a filter\n",
    "           new_h = (H-hh) // stride + 1, new_w = (W-ww) // stride + 1\n",
    "    \"\"\"\n",
    "\n",
    "    c, h, w = x.size\n",
    "    new_h = (h - hh) // stride + 1\n",
    "    new_w = (w - ww) // stride + 1\n",
    "    col = enc_mat(name=name + 'im2col' + str(c * h * w),\n",
    "                  size=(new_h * new_w, c * hh * ww))\n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            for cidx in range(c):\n",
    "                for a in range(hh):\n",
    "                    for b in range(ww):\n",
    "                        col[i * new_w + j,\n",
    "                            cidx * hh * ww + a * ww + b] =\\\n",
    "                            x[cidx][i * stride + a][j * stride + b]\n",
    "    return col\n",
    "def col2im(mul, h_prime, w_prime, C, tgt_out):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "      mul: (h_prime*w_prime*w,F) matrix,\n",
    "           each col should be reshaped to\n",
    "           C*h_prime*w_prime when C>0, or h_prime*w_prime when C = 0\n",
    "      h_prime: reshaped filter height\n",
    "      w_prime: reshaped filter width\n",
    "      C: reshaped filter channel, if 0, reshape the filter to 2D,\n",
    "         Otherwise reshape it to 3D\n",
    "    Returns:\n",
    "      if C == 0: (F,h_prime,w_prime) matrix\n",
    "      Otherwise: (F,C,h_prime,w_prime) matrix\n",
    "    \"\"\"\n",
    "    F = mul.size[1]\n",
    "    h_prime, w_prime = tgt_out.size[0], tgt_out.size[1]\n",
    "    if(C == 1):\n",
    "        for i in range(0, F):\n",
    "            for h_idx in range(0, h_prime):\n",
    "                for w_idx in range(0, w_prime):\n",
    "                    tgt_out[i, h_idx, w_idx] = mul[h_idx * w_prime + w_idx][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = enc_tensor3(size=(2,5, 5), name='sam')\n",
    "i2c = im2col(name='im2col',\n",
    "      x=s, hh=3, ww=3, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['802 BF2 B5D C75 CF4 CD7 0A1 33C FFB 398 1A6 C2F 5F0 F68 2E2 207 F55 AFF', 'BF2 B5D E29 CF4 CD7 A83 33C FFB 7BE 1A6 C2F B59 F68 2E2 436 F55 AFF 0E4', 'B5D E29 37D CD7 A83 C15 FFB 7BE 0A5 C2F B59 892 2E2 436 5F3 AFF 0E4 014', 'C75 CF4 CD7 0A1 33C FFB 10F 1A9 793 5F0 F68 2E2 207 F55 AFF 096 803 CB9', 'CF4 CD7 A83 33C FFB 7BE 1A9 793 68E F68 2E2 436 F55 AFF 0E4 803 CB9 C23', 'CD7 A83 C15 FFB 7BE 0A5 793 68E 241 2E2 436 5F3 AFF 0E4 014 CB9 C23 BC5', '0A1 33C FFB 10F 1A9 793 C99 83C EAA 207 F55 AFF 096 803 CB9 183 355 BC4', '33C FFB 7BE 1A9 793 68E 83C EAA 8ED F55 AFF 0E4 803 CB9 C23 355 BC4 B8B', 'FFB 7BE 0A5 793 68E 241 EAA 8ED 596 AFF 0E4 014 CB9 C23 BC5 BC4 B8B 0DB']\n",
      "[[['802' 'BF2' 'B5D' 'E29' '37D']\n",
      "  ['C75' 'CF4' 'CD7' 'A83' 'C15']\n",
      "  ['0A1' '33C' 'FFB' '7BE' '0A5']\n",
      "  ['10F' '1A9' '793' '68E' '241']\n",
      "  ['C99' '83C' 'EAA' '8ED' '596']]\n",
      "\n",
      " [['398' '1A6' 'C2F' 'B59' '892']\n",
      "  ['5F0' 'F68' '2E2' '436' '5F3']\n",
      "  ['207' 'F55' 'AFF' '0E4' '014']\n",
      "  ['096' '803' 'CB9' 'C23' 'BC5']\n",
      "  ['183' '355' 'BC4' 'B8B' '0DB']]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "st_lst = map(lambda x: map(lambda xt: xt[-3:], x), i2c.name_list)\n",
    "print map(lambda xt: \" \".join(xt), st_lst)\n",
    "i2c_short = np.asarray(map(lambda x: map(lambda xt: map(lambda xst: xst[-3:], xt), x),s.name_list) )\n",
    "print(i2c_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['802 BF2 B5D C75 CF4 CD7 0A1 33C FFB 398 1A6 C2F 5F0 F68 2E2 207 F55 AFF', 'BF2 B5D E29 CF4 CD7 A83 33C FFB 7BE 1A6 C2F B59 F68 2E2 436 F55 AFF 0E4', 'B5D E29 37D CD7 A83 C15 FFB 7BE 0A5 C2F B59 892 2E2 436 5F3 AFF 0E4 014', 'C75 CF4 CD7 0A1 33C FFB 10F 1A9 793 5F0 F68 2E2 207 F55 AFF 096 803 CB9', 'CF4 CD7 A83 33C FFB 7BE 1A9 793 68E F68 2E2 436 F55 AFF 0E4 803 CB9 C23', 'CD7 A83 C15 FFB 7BE 0A5 793 68E 241 2E2 436 5F3 AFF 0E4 014 CB9 C23 BC5', '0A1 33C FFB 10F 1A9 793 C99 83C EAA 207 F55 AFF 096 803 CB9 183 355 BC4', '33C FFB 7BE 1A9 793 68E 83C EAA 8ED F55 AFF 0E4 803 CB9 C23 355 BC4 B8B', 'FFB 7BE 0A5 793 68E 241 EAA 8ED 596 AFF 0E4 014 CB9 C23 BC5 BC4 B8B 0DB']\n",
      "[[['6BC' 'F2B' '773']\n",
      "  ['597' 'E8E' '206']\n",
      "  ['2EA' 'BB7' '63E']]\n",
      "\n",
      " [['35F' 'B50' '373']\n",
      "  ['DB1' '22A' '0DA']\n",
      "  ['87D' 'A61' 'BEE']]\n",
      "\n",
      " [['AD1' '9FC' '248']\n",
      "  ['5D7' '50B' '840']\n",
      "  ['458' 'F7D' '021']]]\n"
     ]
    }
   ],
   "source": [
    "out_cnv = enc_tensor3(name='cnv_out', size=(3, 3, 3))\n",
    "mul = enc_mat(name='cnv_lin_out', size=(9, 3))\n",
    "col2im(mul=mul, h_prime=3, w_prime=3, C=1, tgt_out=out_cnv)\n",
    "\n",
    "st_lst = map(lambda x: map(lambda xt: xt[-3:], x), i2c.name_list)\n",
    "print map(lambda xt: \" \".join(xt), st_lst)\n",
    "i2c_short = np.asarray(map(lambda x: map(lambda xt: map(lambda xst: xst[-3:], xt), x),out_cnv.name_list) )\n",
    "print(i2c_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-aa8107d6a774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_tensor3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv_out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m41\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconv_lyr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv_nn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlayer_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear_layer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_lyr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asanyal/research/SHEEP/scripts/nn_layer.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, weight, inputs, outputs, stride, padding)\u001b[0m\n\u001b[1;32m    127\u001b[0m                           weight=weight, layer_type='conv')\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_weight_validity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asanyal/research/SHEEP/scripts/nn_layer.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         im_col = im2col(name=self.name + 'im2col',\n\u001b[0;32m--> 169\u001b[0;31m                         x=self.inputs, hh=HH, ww=WW, stride=stride)\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mfilter_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m#im_col_t = im_col.transpose((1, 0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asanyal/research/SHEEP/scripts/op_utils.py\u001b[0m in \u001b[0;36mim2col\u001b[0;34m(name, x, hh, ww, stride)\u001b[0m\n\u001b[1;32m     39\u001b[0m                         col[i * new_w + j,\n\u001b[1;32m     40\u001b[0m                             cidx * hh * ww + a * ww + b] =\\\n\u001b[0;32m---> 41\u001b[0;31m                             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asanyal/research/SHEEP/scripts/particles.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    344\u001b[0m         return enc_mat(name=self.name + '_sl_' + str(item),\n\u001b[1;32m    345\u001b[0m                        \u001b[0mname_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomize_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                        size=(self.size[1], self.size[2]))\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asanyal/research/SHEEP/scripts/particles.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, size, randomize_name, name_list)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asanyal/research/SHEEP/scripts/particles.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, name_list)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 self._lst.append([\n\u001b[1;32m    172\u001b[0m                     \u001b[0mvariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     for col_idx in range(self.size[1])])\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asanyal/research/SHEEP/scripts/particles.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, nb, randomize_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrandomize_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m__VERSION__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scripts.nn_layer import conv_layer\n",
    "inp_image = enc_tensor3(name='conv_in', size=(32, 50, 50))\n",
    "out_image = enc_tensor3(name='conv_out', size=(1, 41, 41))\n",
    "weight = (np.random.uniform(size=(32, 32,10,10))> 0.5).astype(int)\n",
    "conv_lyr = conv_layer(name='conv_nn', inputs=inp_image, outputs=out_image, weight=weight)\n",
    "nb = reduce(lambda x,y : x*y, inp_image.size)\n",
    "layer_obj = circuit('linear_layer', conv_lyr, const_inputs=[])\n",
    "layer_obj.write_file(filename='./test_cnn.sheep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1\n",
    "processing_time = np.zeros(samples)\n",
    "for idx in tqdm(range(0, samples)):\n",
    "    inp_arr_val = list(map(lambda x : int(x), np.random.uniform(size=nb*1)> 0.5))\n",
    "    inp_dict = inp_image.get_input_dict(inp_arr_val)\n",
    "    inputs_file = benchmark_utils.write_inputs_file(inp_dict)\n",
    "    results = benchmark_utils.run_circuit('./test_cnn.sheep',inputs_file,\"bool\",\"TFHE\",eval_strategy='parallel')\n",
    "    processing_time[idx] = results['Processing times (s)']['circuit_evaluation']\n",
    "    #out_vars = out_image.get_variables()\n",
    "    #xor_val = (weight == np.asarray([x for x in inp_arr_val]))\n",
    "    #print(xor_val)\n",
    "    #out_bit_vec = np.asarray([int(results['Outputs'][var]) for var in out_vars])\n",
    "    #true_bit_vec = (np.sum(np.asarray(xor_val), axis=1)>nb/2).astype(int)\n",
    "    #assert np.alltrue(out_bit_vec == true_bit_vec)\n",
    "print(processing_time.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
